{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Classes.cognitive_model_agents import PriorsM1, PriorsM2, PriorsM3\n",
    "from Utils.unit_tests import (\n",
    "    test_bar_is_full, \n",
    "    test_bar_has_capacity,\n",
    "    test_alternation\n",
    ")\n",
    "\n",
    "# MODEL = PriorsM1\n",
    "MODEL = PriorsM2\n",
    "# MODEL = PriorsM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inverse_temperature': 10,\n",
       " 0: {'go_prob_(0, 0)': 0.8186621508427763,\n",
       "  'go_prob_(0, 1)': 0.42315897101694633,\n",
       "  'go_prob_(0, 2)': 0.5503363152539641,\n",
       "  'go_prob_(1, 0)': 0.5718753306725387,\n",
       "  'go_prob_(1, 1)': 0.8484580884321544,\n",
       "  'go_prob_(1, 2)': 0.5468158479957163},\n",
       " 1: {'go_prob_(0, 0)': 0.1912002088358119,\n",
       "  'go_prob_(0, 1)': 0.7393336997388277,\n",
       "  'go_prob_(0, 2)': 0.25689381459858207,\n",
       "  'go_prob_(1, 0)': 0.1404982826648027,\n",
       "  'go_prob_(1, 1)': 0.811823382530129,\n",
       "  'go_prob_(1, 2)': 0.49845056625225115}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_agents = 2\n",
    "fixed_parameters = {\n",
    "\t\"threshold\":0.5,\n",
    "\t\"num_agents\":num_agents,\n",
    "}\n",
    "free_parameters = {\n",
    "\t'inverse_temperature':10,\n",
    "}\n",
    "for n in range(num_agents):\n",
    "\tgo_probs = MODEL.create_random_params(num_agents)\n",
    "\tfree_parameters[n] = go_probs\n",
    "free_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Test bar has capacity\n",
      "------------------------------------------------------------\n",
      "Initial state: [0, 0]\n",
      "---------- Round 0 ----------\n",
      "Action preferences in state (0, 0): [0.18133784915722373, 0.8186621508427763]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 1 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 2 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 3 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 4 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 5 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 6 ----------\n",
      "Action preferences in state [0, 0]: [0.18133784915722373, 0.8186621508427763]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 7 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 8 ----------\n",
      "Action preferences in state [0, 0]: [0.18133784915722373, 0.8186621508427763]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 9 ----------\n",
      "Action preferences in state [0, 0]: [0.18133784915722373, 0.8186621508427763]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n"
     ]
    }
   ],
   "source": [
    "agent = MODEL(\n",
    "\tfixed_parameters=fixed_parameters,\n",
    "\tfree_parameters=free_parameters,\n",
    "\tn=0\n",
    ")\n",
    "agent.debug = True\n",
    "test_bar_has_capacity(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Test bar is full\n",
      "------------------------------------------------------------\n",
      "Initial state: [1, 1]\n",
      "---------- Round 0 ----------\n",
      "Action preferences in state (1, 1): [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 1]\n",
      "Payoff action 0: 0\n",
      "---------- Round 1 ----------\n",
      "Action preferences in state [0, 1]: [0.5768410289830537, 0.42315897101694633]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 2 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 3 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 4 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 5 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 6 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 7 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 8 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 9 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n"
     ]
    }
   ],
   "source": [
    "agent = MODEL(\n",
    "\tfixed_parameters=fixed_parameters,\n",
    "\tfree_parameters=free_parameters,\n",
    "\tn=0\n",
    ")\n",
    "agent.debug = True\n",
    "test_bar_is_full(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Test other player alternates\n",
      "------------------------------------------------------------\n",
      "Initial state: [0, 0]\n",
      "---------- Round 0 ----------\n",
      "Action preferences in state (0, 0): [0.18133784915722373, 0.8186621508427763]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 1 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 2 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 3 ----------\n",
      "Action preferences in state [0, 0]: [0.18133784915722373, 0.8186621508427763]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 4 ----------\n",
      "Action preferences in state [1, 1]: [0.15154191156784558, 0.8484580884321544]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 5 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 1]\n",
      "Payoff action 0: 0\n",
      "---------- Round 6 ----------\n",
      "Action preferences in state [0, 1]: [0.5768410289830537, 0.42315897101694633]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 7 ----------\n",
      "Action preferences in state [1, 0]: [0.4281246693274613, 0.5718753306725387]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 1]\n",
      "Payoff action 0: 0\n",
      "---------- Round 8 ----------\n",
      "Action preferences in state [0, 1]: [0.5768410289830537, 0.42315897101694633]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 9 ----------\n",
      "Action preferences in state [0, 0]: [0.18133784915722373, 0.8186621508427763]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n"
     ]
    }
   ],
   "source": [
    "agent = MODEL(\n",
    "\tfixed_parameters=fixed_parameters,\n",
    "\tfree_parameters=free_parameters,\n",
    "\tn=0\n",
    ")\n",
    "agent.debug = True\n",
    "test_alternation(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folder = MODEL.name().replace('-', '/')\n",
    "image_folder = Path('../images', folder)\n",
    "image_folder.mkdir(parents=True, exist_ok=True)\n",
    "data_folder = Path('../data/', folder)\n",
    "data_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_agents = 2\n",
    "fixed_parameters = {\n",
    "\t\"threshold\":0.5,\n",
    "\t\"num_agents\":num_agents,\n",
    "}\n",
    "free_parameters = {\n",
    "\t'inverse_temperature':10,\n",
    "}\n",
    "go_probs = {\n",
    "0: {'go_prob_(0, 0)': 1,\n",
    "  'go_prob_(0, 1)': 1,\n",
    "  'go_prob_(0, 2)': 0,\n",
    "  'go_prob_(1, 0)': 0,\n",
    "  'go_prob_(1, 1)': 0,\n",
    "  'go_prob_(1, 2)': 0},\n",
    " 1: {'go_prob_(0, 0)': 0,\n",
    "  'go_prob_(0, 1)': 1,\n",
    "  'go_prob_(0, 2)': 0,\n",
    "  'go_prob_(1, 0)': 0,\n",
    "  'go_prob_(1, 1)': 0,\n",
    "  'go_prob_(1, 2)': 0}\n",
    "}\n",
    "free_parameters.update(go_probs)\n",
    "simulation_parameters = {\n",
    "\t'num_episodes':100,\n",
    "\t'num_rounds':100,\n",
    "\t'verbose':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inverse_temperature': 10,\n",
       " 0: {'go_prob_(0, 0)': 1,\n",
       "  'go_prob_(0, 1)': 1,\n",
       "  'go_prob_(0, 2)': 0,\n",
       "  'go_prob_(1, 0)': 0,\n",
       "  'go_prob_(1, 1)': 0,\n",
       "  'go_prob_(1, 2)': 0},\n",
       " 1: {'go_prob_(0, 0)': 0,\n",
       "  'go_prob_(0, 1)': 1,\n",
       "  'go_prob_(0, 2)': 0,\n",
       "  'go_prob_(1, 0)': 0,\n",
       "  'go_prob_(1, 1)': 0,\n",
       "  'go_prob_(1, 2)': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df103201b4a42e3ac7c7a9bd3941855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running seeds...:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8e2a72f8c44258857be40c9d044aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting attendance...\n",
      "Plot saved to ../images/Priors/M2/attendance.png\n",
      "Plotting conditional_entropy...\n",
      "Plot saved to ../images/Priors/M2/conditional_entropy.png\n",
      "Plotting entropy...\n",
      "Plot saved to ../images/Priors/M2/entropy.png\n",
      "Plotting efficiency...\n",
      "Plot saved to ../images/Priors/M2/efficiency.png\n",
      "Plotting inequality...\n",
      "Plot saved to ../images/Priors/M2/inequality.png\n",
      "Plotting alternation_index...\n",
      "Plot saved to ../images/Priors/M2/alternation_index.png\n"
     ]
    }
   ],
   "source": [
    "from Utils.interaction import Performer\n",
    "\n",
    "kwargs = {'figsize': (4, 3)}\n",
    "LaTeX_string = Performer.simple_run(\n",
    "    agent_class=MODEL,\n",
    "    fixed_parameters=fixed_parameters,\n",
    "    free_parameters=free_parameters,\n",
    "    simulation_parameters=simulation_parameters,\n",
    "    image_folder=image_folder,\n",
    "    measures=['attendance', 'conditional_entropy', 'entropy', 'efficiency', 'inequality', 'alternation_index'],\n",
    "    seeds=[0],\n",
    "    # kwargs=kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_repositorios",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
