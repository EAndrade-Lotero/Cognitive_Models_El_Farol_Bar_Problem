{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Classes.cognitive_model_agents import PriorsM1, PriorsM2, PriorsM3\n",
    "from Utils.interaction import Performer\n",
    "from Utils.unit_tests import (\n",
    "    test_bar_is_full, \n",
    "    test_bar_has_capacity,\n",
    "    test_alternation\n",
    ")\n",
    "\n",
    "# MODEL = PriorsM1\n",
    "# MODEL = PriorsM2\n",
    "MODEL = PriorsM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inverse_temperature': 18.14856178687022,\n",
       " '0-go_prob_0': 0.9606156446592673,\n",
       " '0-go_prob_1': 0.8718509693812236,\n",
       " '0-go_prob_2': 0.4635161880165546,\n",
       " '0-go_prob_3': 0.5852350169895206,\n",
       " '1-go_prob_0': 0.5110348395536213,\n",
       " '1-go_prob_1': 0.441579777618366,\n",
       " '1-go_prob_2': 0.21576833346623825,\n",
       " '1-go_prob_3': 0.34372341346342394}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_agents = 2\n",
    "fixed_parameters = {\n",
    "\t\"threshold\":0.5,\n",
    "\t\"num_agents\":num_agents,\n",
    "}\n",
    "free_parameters = MODEL.create_random_params(num_agents)\n",
    "free_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Test bar has capacity\n",
      "------------------------------------------------------------\n",
      "Initial state: [0, 0]\n",
      "---------- Round 0 ----------\n",
      "Action preferences in state (0, 0): [0.0393843553407327, 0.9606156446592673]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 1 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 2 ----------\n",
      "Action preferences in state [0, 0]: [0.0393843553407327, 0.9606156446592673]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 3 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 4 ----------\n",
      "Action preferences in state [0, 0]: [0.0393843553407327, 0.9606156446592673]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 5 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 6 ----------\n",
      "Action preferences in state [0, 0]: [0.0393843553407327, 0.9606156446592673]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 7 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n",
      "---------- Round 8 ----------\n",
      "Action preferences in state [0, 0]: [0.0393843553407327, 0.9606156446592673]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 9 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 0]\n",
      "Payoff action 0: 0\n"
     ]
    }
   ],
   "source": [
    "agent = MODEL(\n",
    "\tfixed_parameters=fixed_parameters,\n",
    "\tfree_parameters=free_parameters,\n",
    "\tn=0\n",
    ")\n",
    "agent.debug = True\n",
    "test_bar_has_capacity(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Test bar is full\n",
      "------------------------------------------------------------\n",
      "Initial state: [1, 1]\n",
      "---------- Round 0 ----------\n",
      "Action preferences in state (1, 1): [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 1 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 1]\n",
      "Payoff action 0: 0\n",
      "---------- Round 2 ----------\n",
      "Action preferences in state [0, 1]: [0.12814903061877636, 0.8718509693812236]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 3 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 4 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 5 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 6 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 7 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 8 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 9 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n"
     ]
    }
   ],
   "source": [
    "agent = MODEL(\n",
    "\tfixed_parameters=fixed_parameters,\n",
    "\tfree_parameters=free_parameters,\n",
    "\tn=0\n",
    ")\n",
    "agent.debug = True\n",
    "test_bar_is_full(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Test other player alternates\n",
      "------------------------------------------------------------\n",
      "Initial state: [0, 0]\n",
      "---------- Round 0 ----------\n",
      "Action preferences in state (0, 0): [0.0393843553407327, 0.9606156446592673]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 1 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 1]\n",
      "Payoff action 0: 0\n",
      "---------- Round 2 ----------\n",
      "Action preferences in state [0, 1]: [0.12814903061877636, 0.8718509693812236]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 3 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 1]\n",
      "Payoff action 0: 0\n",
      "---------- Round 4 ----------\n",
      "Action preferences in state [0, 1]: [0.12814903061877636, 0.8718509693812236]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 5 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 6 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 7 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 1]\n",
      "Payoff action 1: -1\n",
      "---------- Round 8 ----------\n",
      "Action preferences in state [1, 1]: [0.41476498301047937, 0.5852350169895206]\n",
      "Chosen action: 1\n",
      "State arrived: [1, 0]\n",
      "Payoff action 1: 1\n",
      "---------- Round 9 ----------\n",
      "Action preferences in state [1, 0]: [0.5364838119834454, 0.4635161880165546]\n",
      "Chosen action: 0\n",
      "State arrived: [0, 1]\n",
      "Payoff action 0: 0\n"
     ]
    }
   ],
   "source": [
    "agent = MODEL(\n",
    "\tfixed_parameters=fixed_parameters,\n",
    "\tfree_parameters=free_parameters,\n",
    "\tn=0\n",
    ")\n",
    "agent.debug = True\n",
    "test_alternation(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folder = MODEL.name().replace('-', '/')\n",
    "image_folder = Path('../images', folder)\n",
    "image_folder.mkdir(parents=True, exist_ok=True)\n",
    "data_folder = Path('../data/', folder)\n",
    "data_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_agents = 2\n",
    "fixed_parameters = {\n",
    "\t\"threshold\":0.5,\n",
    "\t\"num_agents\":num_agents,\n",
    "}\n",
    "free_parameters = MODEL.create_random_params(num_agents)\n",
    "simulation_parameters = {\n",
    "\t'num_episodes':10,\n",
    "\t'num_rounds':10,\n",
    "\t'verbose':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inverse_temperature': 31.17430654670635,\n",
       " '0-go_prob_0': 0.030848995090947184,\n",
       " '0-go_prob_1': 0.339911676236075,\n",
       " '0-go_prob_2': 0.4048825200035291,\n",
       " '0-go_prob_3': 0.1349975387919352,\n",
       " '1-go_prob_0': 0.5599851712083544,\n",
       " '1-go_prob_1': 0.4781409099187721,\n",
       " '1-go_prob_2': 0.18418786081507132,\n",
       " '1-go_prob_3': 0.9392718691094877}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114ec0441c9b4d7299b63719255e2bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running seeds...:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab5cdff5fdd4c6fb647cf98981491c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LaTeX_string = Performer.simple_run(\n",
    "    agent_class=MODEL,\n",
    "    fixed_parameters=fixed_parameters,\n",
    "    free_parameters=free_parameters,\n",
    "    simulation_parameters=simulation_parameters,\n",
    "    image_folder=image_folder,\n",
    "    measures=['render'],\n",
    "    seeds=[0]\n",
    "    # kwargs=kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06155f09412044b2bcf8cb8daf2cb152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting attendance...\n",
      "Plot saved to ..\\images\\Priors\\M3\\attendance_1.png\n",
      "Plotting conditional_entropy...\n",
      "Plot saved to ..\\images\\Priors\\M3\\conditional_entropy_1.png\n",
      "Plotting entropy...\n",
      "Plot saved to ..\\images\\Priors\\M3\\entropy_1.png\n",
      "Plotting efficiency...\n",
      "Plot saved to ..\\images\\Priors\\M3\\efficiency_1.png\n",
      "Plotting inequality...\n",
      "Plot saved to ..\\images\\Priors\\M3\\inequality_1.png\n",
      "Plotting alternation_index...\n",
      "Plot saved to ..\\images\\Priors\\M3\\alternation_index_1.png\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'figsize': (4, 3)}\n",
    "LaTeX_string = Performer.simple_plots(\n",
    "    agent_class=MODEL,\n",
    "    fixed_parameters=fixed_parameters,\n",
    "    free_parameters=free_parameters,\n",
    "    simulation_parameters=simulation_parameters,\n",
    "    image_folder=image_folder,\n",
    "    measures=[\n",
    "        'attendance', \n",
    "        'conditional_entropy', \n",
    "        'entropy', \n",
    "        'efficiency', \n",
    "        'inequality', \n",
    "        'alternation_index'\n",
    "    ],\n",
    "    # kwargs=kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
